{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ea3c82f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'datadetox' from 'c:\\\\Users\\\\USER\\\\Desktop\\\\GitHub\\\\Brasileirao-Analise\\\\3. Source Code\\\\Transformed\\\\datadetox.py'>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip uninstall spellchecker -y\n",
    "# !pip install pyspellchecker\n",
    "# !pip install unidecode\n",
    "# !pip install scikit-learn  # For cosine_similarity and numpy (it's a dependency)\n",
    "# !pip install sentence-transformers\n",
    "# !pip install pandas\n",
    "#!pip install ipywidgets\n",
    "\n",
    "import re\n",
    "import unidecode\n",
    "from spellchecker import SpellChecker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datadetox as detox\n",
    "import importlib\n",
    "importlib.reload(detox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09036e",
   "metadata": {},
   "source": [
    "Leitura e padronização de colunas de chaves primarias para concatenação de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7a17ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Já é datetime64, mantido como está.\n",
      "DataFrame 1: Convertendo padrão com '/'\n",
      "DataFrame 2: Convertendo padrão com '/'\n",
      "DataFrame 3: Convertendo padrão com '/'\n",
      "DataFrame 4: Convertendo padrão ISO com '-'\n",
      "DataFrame 5: Já é datetime64, mantido como está.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path = r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed'\n",
    "\n",
    "#Games \n",
    "df_list = []\n",
    "for i in range(1, 7):\n",
    "    df = pd.read_excel(path + f'\\\\0{i}_games.xlsx')\n",
    "    df_list.append(df)\n",
    "\n",
    "#fitragem série B comjumto 5\n",
    "df_list[4] = df_list[4][df_list[4]['Série']=='A']\n",
    "\n",
    "# mapeamento_colunas chave primária\n",
    "mapeamento_colunas = {  'data': 'Data','Date': 'Data','data_partida': 'Data',\n",
    "                        'time_mandante': 'Mandante','mandante': 'Mandante','Home': 'Mandante',\n",
    "                        'time_visitante': 'Visitante','visitante': 'Visitante','Away': 'Visitante'}\n",
    "    \n",
    "\n",
    "df_list = [df.rename(columns=mapeamento_colunas) for df in df_list]\n",
    "\n",
    "df_list = detox.padronizar_datas(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f798d",
   "metadata": {},
   "source": [
    "Unir todos os DFs com agrupamento por colunas, Data, Mandante e Visitante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c16a3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapear cluber qeu o filtro BERT nao resolve (manualmente)\n",
    "clubes_map_inicial = {  \"America-RN\":\"América Natal\",\"América-RN\":\"América Natal\",\"América rn\":\"América Natal\",\n",
    "                        \"Joinvile\":\"Joinville\",\n",
    "                        \"Atlético pr\":\"Athlético-PR\",\"Atlético-PR\":\"Athlético-PR\", \n",
    "                        \"Grêmio Prudente\":\"Barueri\",\"Grêmio prudente\":\"Barueri\",\"Gremio Prudente\":\"Barueri\"}\n",
    "\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_map_inicial)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_map_inicial)\n",
    "\n",
    "# listar clubes Mandantes e visitantes, para agrupar ortograficamente\n",
    "clubes_unicos = []\n",
    "for df in df_list:\n",
    "    unicos_por_bd = pd.unique(np.concatenate([df['Mandante'].values, df['Visitante'].values])).tolist()\n",
    "    clubes_unicos = list(set(clubes_unicos) | set(unicos_por_bd))\n",
    "\n",
    "clubes_value_dict = [   \"América Mineiro\", \"América Natal\", \"Athletico Paranaense\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Avaí\", \"Bahia\", \n",
    "                        \"Barueri\", \"Botafogo\", \"Red Bull Bragantino\", \"Brasiliense\", \"Ceará\", \n",
    "                        \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"CSA\", \"Cuiabá\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \n",
    "                        \"Fortaleza\",\"Guarani\", \"Goiás\", \"Grêmio\", \"Grêmio Prudente\", \"Internacional\", \"Ipatinga\", \"Joinville\", \"Juventude\",\"Mirassol\", \"Náutico\", \n",
    "                        \"Palmeiras\", \"Paraná\", \"Paysandu\", \"Ponte Preta\", \"Portuguesa\", \"Santa Cruz\", \"Santo André\", \"Santos\", \"São Caetano\", \"São Paulo\", \n",
    "                        \"Sport Recife\", \"Vasco da Gama\", \"Vitória\"]\n",
    "\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "clubes_corrigidos = detox.corrigir_times_semanticamente(clubes_unicos, clubes_value_dict,modelo)\n",
    "clubes_dict = detox.gerar_dicionario_mapeamento(clubes_corrigidos, limite=0.0)\n",
    "\n",
    "# corrigindo e agrupando clubes em todos os dataframes\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_dict)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_dict)\n",
    "\n",
    "# unindo todos os dfs com merge on=['Data','Mandante','Visitante']\n",
    "df_merged = pd.DataFrame(columns=['Data','Mandante','Visitante'])\n",
    "for i,df in enumerate(df_list):\n",
    "    df_merged = pd.merge(df_merged, df, how='outer', on=['Data','Mandante','Visitante'],suffixes=('', f'_{i}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9a0b8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "import datetime as dt\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Criar edições dos campeonatos visto que 2020 foi ate 2021\n",
    "mask = (df['Data'] > dt.datetime(2020, 8, 1)) & (df['Data'] < dt.datetime(2021, 2, 28))\n",
    "df.loc[mask, 'edition'] = 2020\n",
    "df.loc[~mask, 'edition'] = df.loc[~mask, 'Data'].dt.year\n",
    "\n",
    "df.sort_values(by=['Mandante', 'Visitante','edition','Data'], ascending=[True, True, True, True], inplace=True)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "dcf1175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1468\\521695030.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1468\\521695030.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1468\\521695030.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "# Agrupar e aplicar a função\n",
    "df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
    "\n",
    "# Aplica o agrupamento e mescla as linhas sem conflito\n",
    "df_mesclado = (\n",
    "    df_ajustado.groupby(['Data', 'Mandante', 'Visitante', 'edition'], group_keys=False)\n",
    "      .apply(detox.mesclar_linhas_sem_conflito)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "df_mesclado.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Agrupamento_unico.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2006 = df_list.copy()\n",
    "df_2006.pop(0)\n",
    "df_2006.pop(-2)\n",
    "for df in df_2006:\n",
    "    df['Ano_Part'] = df['Data'].dt.year\n",
    "    df = df[df['Ano_Part'] == 2010]  \n",
    "\n",
    "for df in df_2006:\n",
    "    df = df[(df['Mandante'] == 'Goiás') & (df['Visitante'] == 'Flamengo') & (df['Ano_Part'] == 2010)]\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "874a9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_mesclado.copy()\n",
    "pd.set_option('display.max_info_columns', 200)  # ou None para infinito\n",
    "#df.info()\n",
    "\n",
    "df['N_partidas_mandante'] = df.groupby(['edition', 'Mandante'])['Mandante'].transform('count')\n",
    "df['N_partidas_visitante'] = df.groupby(['edition','Visitante'])['Visitante'].transform('count')\n",
    "df = df[df['edition']<2024] #removendo 2024\n",
    "\n",
    "df = df[df['edition']==2010]\n",
    "# df['Mandante'].value_counts()\n",
    "\n",
    "# df = df[df['Mandante'] == 'Goiás'] #removendo jogos onde mandante e visitante sao iguais\n",
    "# display(df.sort_values(by='Visitante', ascending=True))     \n",
    "                                                                \n",
    "# df['edition'].value_counts()\n",
    "# display(df[(df['edition']==2010) & (df['N_partidas_mandante']>19) & (df['N_partidas_visitante']>19)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3e7db74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004: São Paulo, 24\n",
      "2005: Cruzeiro, 22\n",
      "2005: Fluminense, 22\n",
      "2005: Internacional, 22\n",
      "2005: Juventude, 23\n",
      "2005: Paysandu, 22\n",
      "2005: Ponte Preta, 22\n",
      "2005: Santos, 22\n",
      "2005: São Paulo, 22\n",
      "2005: Vasco da Gama, 23\n",
      "2007: América Natal, 20\n",
      "2007: Atlético Mineiro, 21\n",
      "2007: Botafogo, 20\n",
      "2007: Corinthians, 20\n",
      "2007: Cruzeiro, 20\n",
      "2007: Figueirense, 21\n",
      "2007: Flamengo, 20\n",
      "2007: Fluminense, 20\n",
      "2007: Internacional, 20\n",
      "2007: Juventude, 21\n",
      "2007: Paraná, 21\n",
      "2007: Santos, 20\n",
      "2007: Sport Recife, 22\n",
      "2007: São Paulo, 21\n",
      "2007: Vasco da Gama, 22\n",
      "2008: Athletico Paranaense, 20\n",
      "2008: Cruzeiro, 20\n",
      "2008: Figueirense, 20\n",
      "2008: Flamengo, 20\n",
      "2008: Grêmio, 20\n",
      "2008: Ipatinga, 20\n",
      "2008: Náutico, 20\n",
      "2008: Palmeiras, 20\n",
      "2008: Santos, 20\n",
      "2008: Sport Recife, 20\n",
      "2008: São Paulo, 20\n",
      "2009: Atlético Mineiro, 20\n",
      "2009: Barueri, 20\n",
      "2009: Botafogo, 20\n",
      "2009: Coritiba, 20\n",
      "2009: Fluminense, 20\n",
      "2009: Goiás, 20\n",
      "2009: Internacional, 20\n",
      "2009: Palmeiras, 20\n",
      "2010: Athletico Paranaense, 29\n",
      "2010: Atlético Goianiense, 20\n",
      "2010: Atlético Mineiro, 30\n",
      "2010: Avaí, 28\n",
      "2010: Barueri, 29\n",
      "2010: Botafogo, 31\n",
      "2010: Ceará, 20\n",
      "2010: Corinthians, 29\n",
      "2010: Coritiba, 10\n",
      "2010: Cruzeiro, 29\n",
      "2010: Flamengo, 28\n",
      "2010: Fluminense, 28\n",
      "2010: Goiás, 29\n",
      "2010: Grêmio, 28\n",
      "2010: Guarani, 20\n",
      "2010: Internacional, 30\n",
      "2010: Náutico, 10\n",
      "2010: Palmeiras, 28\n",
      "2010: Santo André, 9\n",
      "2010: Santos, 29\n",
      "2010: Sport Recife, 10\n",
      "2010: São Paulo, 29\n",
      "2010: Vitória, 29\n",
      "2016: Figueirense, 20\n",
      "2016: Ponte Preta, 20\n",
      "2017: Grêmio, 20\n",
      "2020: Coritiba, 20\n",
      "2020: Fortaleza, 20\n",
      "2022: Atlético Mineiro, 20\n",
      "2024: Athletico Paranaense, 13\n",
      "2024: Atlético Goianiense, 14\n",
      "2024: Atlético Mineiro, 14\n",
      "2024: Bahia, 14\n",
      "2024: Botafogo, 14\n",
      "2024: Corinthians, 15\n",
      "2024: Criciúma, 14\n",
      "2024: Cruzeiro, 14\n",
      "2024: Cuiabá, 14\n",
      "2024: Flamengo, 15\n",
      "2024: Fluminense, 14\n",
      "2024: Fortaleza, 15\n",
      "2024: Grêmio, 15\n",
      "2024: Internacional, 13\n",
      "2024: Juventude, 14\n",
      "2024: Palmeiras, 14\n",
      "2024: Red Bull Bragantino, 13\n",
      "2024: São Paulo, 15\n",
      "2024: Vasco da Gama, 14\n",
      "2024: Vitória, 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cont_man = df_mesclado.groupby(['edition', 'Mandante']).size().reset_index(name='qtd_m')\n",
    "cont_vis = df_mesclado.groupby(['edition', 'Visitante']).size().reset_index(name='qtd_v')\n",
    "#display(cont_man,cont_vis)\n",
    "#display(cont_man)\n",
    "\n",
    "mapeamento = {ano: 23 for ano in [2003, 2004]}\n",
    "mapeamento.update({2005: 21})\n",
    "mapeamento.update({ano: 19 for ano in range(2006, 2025)})\n",
    "\n",
    "edt = list(map(int,df_mesclado['edition'].unique()))\n",
    "for edition in edt:\n",
    "    df_aux = cont_man[cont_man['edition'] == edition]\n",
    "    df_aux2 = cont_vis[cont_vis['edition'] == edition]\n",
    "    valor_mapeado = mapeamento.get(edition)\n",
    "    for i in range(len(df_aux)):\n",
    "        if df_aux.iloc[i]['qtd_m'] != valor_mapeado:\n",
    "            print(f'{edition}: {df_aux.iloc[i][\"Mandante\"]}, {df_aux.iloc[i][\"qtd_m\"]}')\n",
    "        # if df_aux2.iloc[i]['qtd_v'] != valor_mapeado:\n",
    "        #     print(f'{df_aux2.iloc[i][\"Visitante\"]}, {df_aux2.iloc[i][\"qtd_v\"]}')\n",
    "\n",
    "\n",
    "\n",
    "# for edition in edt:\n",
    "#     df_aux = df[df['edition'] == edition]\n",
    "#     for i in range(len(df_aux)):\n",
    "#         if not df_aux.iloc[i]['Mandante'] == mapeamento[edition]:\n",
    "#             print(df_aux.iloc['Mandante'][i], df_aux.iloc['qtd_m'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bad9ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitante\n",
      "Santos                  20\n",
      "Vasco da Gama           20\n",
      "Athletico Paranaense    20\n",
      "Fluminense              20\n",
      "Cruzeiro                20\n",
      "Goiás                   20\n",
      "São Paulo               20\n",
      "Grêmio                  19\n",
      "Vitória                 19\n",
      "Barueri                 19\n",
      "Atlético Mineiro        19\n",
      "Atlético Goianiense     19\n",
      "Flamengo                19\n",
      "Guarani                 19\n",
      "Avaí                    19\n",
      "Internacional           19\n",
      "Corinthians             19\n",
      "Ceará                   19\n",
      "Botafogo                19\n",
      "Palmeiras               19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df_mesclado.copy()\n",
    "#df = df[(df['edition'] == 2010) ]\n",
    "df = df[(df['edition'] == 2010) & \n",
    "        (~df['Mandante'].isin(['Náutico', 'Sport Recife','Santo André', 'Coritiba'])) & \n",
    "        (~df['Visitante'].isin(['Náutico', 'Sport Recife','Santo André', 'Coritiba']))]\n",
    "print(df['Visitante'].value_counts())\n",
    "#display(df.sort_values(by=['Mandante','Visitante'], ascending=[True,True]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
