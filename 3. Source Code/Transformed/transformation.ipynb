{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3c82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip uninstall spellchecker -y\n",
    "# !pip install pyspellchecker\n",
    "# !pip install unidecode\n",
    "# !pip install scikit-learn  # For cosine_similarity and numpy (it's a dependency)\n",
    "# !pip install sentence-transformers\n",
    "# !pip install pandas\n",
    "# !pip install ipywidgets\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datadetox as detox\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09036e",
   "metadata": {},
   "source": [
    "Leitura e padronização de colunas de chaves primarias para concatenação de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a17ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Já é datetime64, mantido como está.\n",
      "DataFrame 1: Já é datetime64, mantido como está.\n",
      "DataFrame 2: Já é datetime64, mantido como está.\n",
      "DataFrame 3: Já é datetime64, mantido como está.\n",
      "DataFrame 4: Já é datetime64, mantido como está.\n",
      "DataFrame 5: Já é datetime64, mantido como está.\n",
      "DataFrame 6: Já é datetime64, mantido como está.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "path = r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed'\n",
    "\n",
    "#Games \n",
    "df_list = []\n",
    "for i in range(1, 8):\n",
    "    df = pd.read_excel(path + f'\\\\0{i}_games.xlsx')\n",
    "    df_list.append(df)\n",
    "\n",
    "\n",
    "#fitragem série B conjunto 5\n",
    "df_list[6] = df_list[6][df_list[6]['Série']=='A']\n",
    "\n",
    "# mapeamento_colunas chave primária\n",
    "mapeamento_colunas = {  'data': 'Data','Date': 'Data','data_partida': 'Data',\n",
    "                        'time_mandante': 'Mandante','mandante': 'Mandante','Home': 'Mandante',\n",
    "                        'time_visitante': 'Visitante','visitante': 'Visitante','Away': 'Visitante'}\n",
    "    \n",
    "\n",
    "df_list = [df.rename(columns=mapeamento_colunas) for df in df_list]\n",
    "\n",
    "df_list = detox.padronizar_datas(df_list)\n",
    "\n",
    "for i, df_save in enumerate(df_list):\n",
    "    df_save.to_excel(path + f'\\\\0{i+1}_games.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f798d",
   "metadata": {},
   "source": [
    "Unir todos os DFs com agrupamento por colunas, Data, Mandante e Visitante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c16a3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapear cluber qeu o filtro BERT nao resolve (manualmente)\n",
    "clubes_map_inicial = {  \"America-RN\":\"América Natal\",\"América-RN\":\"América Natal\",\"América rn\":\"América Natal\",\n",
    "                        \"Joinvile\":\"Joinville\",\n",
    "                        \"Atlético pr\":\"Athlético-PR\",\"Atlético-PR\":\"Athlético-PR\", \n",
    "                        \"Grêmio Prudente\":\"Barueri\",\"Grêmio prudente\":\"Barueri\",\"Gremio Prudente\":\"Barueri\"}\n",
    "\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_map_inicial)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_map_inicial)\n",
    "\n",
    "# listar clubes Mandantes e visitantes, para agrupar ortograficamente\n",
    "clubes_unicos = []\n",
    "for df in df_list:\n",
    "    unicos_por_bd = pd.unique(np.concatenate([df['Mandante'].values, df['Visitante'].values])).tolist()\n",
    "    clubes_unicos = list(set(clubes_unicos) | set(unicos_por_bd))\n",
    "\n",
    "clubes_value_dict = [   \"América Mineiro\", \"América Natal\", \"Athletico Paranaense\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Avaí\", \"Bahia\", \n",
    "                        \"Barueri\", \"Botafogo\", \"Red Bull Bragantino\", \"Brasiliense\", \"Ceará\", \n",
    "                        \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"CSA\", \"Cuiabá\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \n",
    "                        \"Fortaleza\",\"Guarani\", \"Goiás\", \"Grêmio\", \"Grêmio Prudente\", \"Internacional\", \"Ipatinga\", \"Joinville\", \"Juventude\",\"Mirassol\", \"Náutico\", \n",
    "                        \"Palmeiras\", \"Paraná\", \"Paysandu\", \"Ponte Preta\", \"Portuguesa\", \"Santa Cruz\", \"Santo André\", \"Santos\", \"São Caetano\", \"São Paulo\", \n",
    "                        \"Sport Recife\", \"Vasco da Gama\", \"Vitória\"]\n",
    "\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "clubes_corrigidos = detox.corrigir_times_semanticamente(clubes_unicos, clubes_value_dict,modelo)\n",
    "clubes_dict = detox.gerar_dicionario_mapeamento(clubes_corrigidos, limite=0.0)\n",
    "\n",
    "# corrigindo e agrupando clubes em todos os dataframes\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_dict)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_dict)\n",
    "\n",
    "# unindo todos os dfs com merge on=['Data','Mandante','Visitante']\n",
    "df_merged = pd.DataFrame(columns=['Data','Mandante','Visitante'])\n",
    "for i,df in enumerate(df_list):\n",
    "    df_merged = pd.merge(df_merged, df, how='outer', on=['Data','Mandante','Visitante'],suffixes=('', f'_{i}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a0b8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "import datetime as dt\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Criar edições dos campeonatos visto que 2020 foi ate 2021\n",
    "mask = (df['Data'] > dt.datetime(2020, 8, 1)) & (df['Data'] < dt.datetime(2021, 2, 28))\n",
    "df.loc[mask, 'edition'] = 2020\n",
    "df.loc[~mask, 'edition'] = df.loc[~mask, 'Data'].dt.year\n",
    "\n",
    "df.sort_values(by=['Mandante', 'Visitante','edition','Data'], ascending=[True, True, True, True], inplace=True)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcf1175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_group = df_mesclado.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13072\\2427877954.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "# Agrupar e aplicar a função\n",
    "df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
    "\n",
    "# Aplica o agrupamento e mescla as linhas sem conflito\n",
    "df_mesclado = (\n",
    "    df_ajustado.groupby(['Data', 'Mandante', 'Visitante', 'edition'], group_keys=False)\n",
    "      .apply(detox.mesclar_linhas_sem_conflito)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "df_mesclado = df_mesclado[df_mesclado['edition']<2024]\n",
    "\n",
    "df_group = df_mesclado.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(\n",
    "    lambda group: detox.ajustar_datas_semdiff(group,keep=True))\n",
    "\n",
    "df_mesclado2 = (\n",
    "    df_group.groupby(['Data', 'Mandante', 'Visitante', 'edition'], group_keys=False)\n",
    "      .apply(detox.mesclar_linhas_sem_conflito)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "df_mesclado2.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Agrupamento_unico.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2b352",
   "metadata": {},
   "source": [
    "Garantindo partidas por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "340f62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edições com número desigual de partidas por time: Series([], Name: n_partidas, dtype: int64)\n",
      "Edições com número desigual de partidas por time: Series([], Name: n_partidas, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "importlib.reload(detox)\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Agrupamento_unico.xlsx')\n",
    "\n",
    "#ajustando sao paulo e sao caetano jogo interrompido\n",
    "df.drop(1007, inplace=True)\n",
    "\n",
    "# # ajustando jogo do flamengo\n",
    "# df.loc[2835, 'Data'] = pd.to_datetime('2009-11-07')\n",
    "# df.drop(2834, inplace=True)\n",
    "\n",
    "# # ajustando jogo do BOTAFOGO\n",
    "# df.loc[1969, 'Data'] = pd.to_datetime('2009-07-29')\n",
    "# df.drop(1968, inplace=True)\n",
    "\n",
    "# # ajustando jogo da chapecoense\n",
    "# df.drop(5753, inplace=True)\n",
    "\n",
    "#2005\n",
    "df.drop([1137,1137,1207,1231,1257,1284,1307,1310,1328,1341,1375,1379], inplace=True)\n",
    "df.loc[1138, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1208, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1232, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1258, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1285, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1308, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1311, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1329, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1342, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1376, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1380, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "\n",
    "#2006 \n",
    "df.drop([1695,1697,1724,1726], inplace=True)\n",
    "\n",
    "#2007 \n",
    "df.drop([1973,1974,1975], inplace=True)\n",
    "\n",
    "#2009 \n",
    "df.drop([2839], inplace=True)\n",
    "\n",
    "detox.verifica_partidas_edi(df,'edition','Mandante')\n",
    "detox.verifica_partidas_edi(df,'edition','Visitante')\n",
    "\n",
    "df.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Num_partidas.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3af196",
   "metadata": {},
   "source": [
    "Meslclando Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b49ebcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Num_partidas.xlsx')\n",
    "\n",
    "gols_mandante = [\"gols_mandante\",\"mandante_Placar\",\"Mandante Placar\",\"mandante_Placar_3\",\"Gol Mandante\",\"placar_mandante\"]\n",
    "gols_visitante = [\"gols_visitante\",\"visitante_Placar\",\"Visitante Placar\",\"visitante_Placar_3\",\"Gol Visitante\",\"placar_visitante\"]\n",
    "colunas_hora = [\"Horário\", \"hora\", \"hora_3\", \"Hora\", \"hora_partida\"]\n",
    "arenas_col = ['arena', 'Arena', 'arena_3', 'Estádio', 'estadio', 'estadio_5']\n",
    "rodada_col = ['rodada','rodata','Rodada','rodata_3','rodada_5','Rodada_6']\n",
    "\n",
    "for col in colunas_hora:\n",
    "    df[col] = df[col].str.replace(r'h', ':', regex=True)\n",
    "    df[col] = pd.to_datetime(df[col], format='%H:%M')\n",
    "\n",
    "df[gols_mandante].nunique(axis=1,dropna=True).value_counts()\n",
    "df[gols_visitante].nunique(axis=1,dropna=True).value_counts()\n",
    "df[colunas_hora].nunique(axis=1,dropna=True).value_counts()\n",
    "\n",
    "df['gols_mandante_moda'] = df[gols_mandante].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "df['gols_visitante_moda'] = df[gols_visitante].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "df['horario'] = df[colunas_hora].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "df.drop(columns=gols_mandante+gols_visitante+colunas_hora, inplace=True)\n",
    "\n",
    "for i in range(1,10):\n",
    "    df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=i,div=15))\n",
    "\n",
    "df.loc[2191, 'horario'] = pd.to_datetime('2009-10-19 19:00') #horario meio noite\n",
    "df['horario'] = df['horario'].dt.time\n",
    "\n",
    "for col in arenas_col:\n",
    "    df[col] = df[col].apply(detox.normalizar_texto)\n",
    "    df[col] = df[col].str.replace(r'\\bestadio\\b', '', regex=True).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\(\\*pf\\)', '', regex=True).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\*\\(pf\\)', '', regex=True)\n",
    "\n",
    "mapeamento_estadios = detox.ler_json_as_dict('arenas_dict.json')\n",
    "\n",
    "for arena in arenas_col:\n",
    "    df[arena] = df[arena].replace(mapeamento_estadios)\n",
    "\n",
    "df['Arena_moda'] = df[arenas_col].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "df.drop(columns=arenas_col, inplace=True)\n",
    "\n",
    "df['Rodada_moda'] = df[rodada_col].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "df.drop(columns=rodada_col, inplace=True)\n",
    "\n",
    "\n",
    "drop_list = [\"mandante_Estado\", \"mandante_Estado_3\", \"Estado Mandante\", \"UF\", \"UF Mandante\", \"Cidade\", \"Turno\", \"Dia da Semana\", \"Série\",\n",
    "             \"ano_campeonato\",\"valor_equipe_titular_mandante\",\"valor_equipe_titular_visitante\",\"idade_media_titular_mandante\",\n",
    "             \"idade_media_titular_mandante\", \"idade_media_titular_visitante\", \"gols_1_tempo_mandante\", \"gols_1_tempo_visitante\", \"escanteios_mandante\", \"escanteios_visitante\", \n",
    "             \"faltas_mandante\", \"faltas_visitante\", \"chutes_bola_parada_mandante\", \"chutes_bola_parada_visitante\", \"defesas_mandante\", \"defesas_visitante\", \"impedimentos_mandante\", \"impedimentos_visitante\", \"chutes_mandante\", \n",
    "             \"chutes_visitante\", \"chutes_fora_mandante\", \"chutes_fora_visitante\", \"ID\",\"ID_3\",\"Season\", \"HG\", \"AG\", \"PSCH\", \"PSCD\", \"PSCA\", \"MaxCH\", \"MaxCD\", \"MaxCA\", \"AvgCH\", \"AvgCD\", \"AvgCA\", \"BFECH\", \"BFECD\", \"BFECA\", \"mandante_gols_fora_casa\", \"mandante_empates_fora_casa\",\n",
    "             \"mandante_total_jogos\", \"mandante_gols_casa\", \"mandante_jogos_fora_casa\", \"mandante_vitorias_casa\", \"mandante_derrotas_casa\", \"mandante_total_pontos\", \"mandante_empates_casa\", \"mandante_pontos_fora_casa\", \"mandante_total_gols_sofridos\", \"mandante_total_vitorias\", \"mandante_vitorias_fora_casa\", \"mandante_total_derrotas\", \n",
    "             \"mandante_pontos_casa\", \"mandante_derrotas_fora_casa\", \"mandante_total_gols_marcados\", \"mandante_jogos_casa\", \"mandante_total_empates\", \"visitante_gols_fora_casa\", \"visitante_empates_fora_casa\", \"visitante_total_jogos\", \"visitante_gols_casa\", \"visitante_jogos_fora_casa\", \"visitante_vitorias_casa\", \"visitante_derrotas_casa\", \n",
    "             \"visitante_total_pontos\", \"visitante_empates_casa\", \"visitante_pontos_fora_casa\", \"visitante_total_gols_sofridos\", \"visitante_total_vitorias\", \"visitante_vitorias_fora_casa\", \"visitante_total_derrotas\", \"Número do Jogo\",\"Temporada\",\"Gols no Jogo\",\n",
    "             \"visitante_pontos_casa\", \"visitante_derrotas_fora_casa\", \"visitante_total_gols_marcados\", \"visitante_jogos_casa\", \"visitante_total_empates\",\n",
    "             \"Placar\",\"Link do Jogo\",\"Data de Início da Consulta\",\"Data de Fim da Consulta\",    \"UF Visitante\", \"Resultado\", \"Resultado Mandante\", \"Resultado Visitante\", \"ano campeonato\",\n",
    "            \"tecnico_mandante\", \"tecnico_visitante\", \"colocacao_mandante\", \"colocacao_visitante\",\n",
    "            \"formacao_mandante\", \"formacao_visitante\", \"tecnico_mandante_1\", \"tecnico_visitante_1\",\n",
    "            \"vencedor\", \"visitante_Estado\", \"Dia\", \"Vencedor\", \"Estado Visitante\", \"Estado Vencedor\",\n",
    "            \"formacao_mandante_3\", \"formacao_visitante_3\", \"tecnico_mandante_3\", \"tecnico_visitante_3\",\n",
    "            \"vencedor_3\", \"visitante_Estado_3\", \"Country\", \"League\", \"Time\", \"Res\",\"resultado\"\n",
    "]\n",
    "df.drop(columns=drop_list, inplace=True)\n",
    "\n",
    "# ajustando rodadas que ficaram erradas\n",
    "df.loc[(df['Mandante'] == 'Athletico Paranaense') & (df['Visitante'] == 'Santos') & (df['edition'] == 2003), 'Rodada_moda'] = 14 \n",
    "df.loc[(df['Mandante'] == 'Cruzeiro') & (df['Visitante'] == 'Botafogo') & (df['edition'] == 2007), \n",
    "       ['Rodada_moda','Data','publico','publico_max','gols_mandante_moda','gols_visitante_moda','arbitro']] = [15,pd.to_datetime('2009-7-29'),13302,19226,3,2,'Leonardo Gaciba da Silva'] \n",
    "\n",
    "df.loc[(df['Mandante'] == 'Botafogo') & (df['Visitante'] == 'Flamengo') & (df['edition'] == 2009), \n",
    "       ['Rodada_moda','Data','arbitro','publico','gols_mandante_moda','gols_visitante_moda']] = [31,pd.to_datetime('2009-10-25'),'Luiz Antônio Silva dos Santos',25192,0,1] \n",
    "\n",
    "df.loc[(df['Mandante'] == 'Flamengo') & (df['Visitante'] == 'Botafogo') & (df['edition'] == 2009), \n",
    "       ['Rodada_moda','horario']] = [12,pd.to_datetime('18:30:00', format='%H:%M:%S')] \n",
    "\n",
    "df.loc[(df['Mandante'] == 'Chapecoense') & (df['Visitante'] == 'Atlético Mineiro') & (df['edition'] == 2016), 'publico'] = 0 \n",
    "\n",
    "df.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Feat_eng.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ba3e7",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9620d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Feat_eng.xlsx')\n",
    "\n",
    "#criar colunas de pontuação na rodada\n",
    "df.rename(columns={'gols_mandante_moda': 'Placar mandante', 'gols_visitante_moda': 'Placar visitante', 'Rodada_moda': 'Rodada', 'Arena_moda': 'Arena'}, inplace=True)\n",
    "df = detox.distribuir_pontos(df,'Placar mandante','Placar visitante')\n",
    "\n",
    "df.sort_values(by=['edition','Rodada','Data'],ascending=[True, True,True], inplace=True,ignore_index=True)\n",
    "season_list = list(set(df['edition']))\n",
    "for ano in season_list:\n",
    "    df = detox.pont_acumulada(df,ano)\n",
    "\n",
    "df.rename(columns={\"publico_max\":\"publico disponivel\",\"edition\":\"temporada\",\"publico\":\"publico pagante\"},inplace=True)\n",
    "\n",
    "map_publico_maximo = detox.ler_json_as_dict('estadios.json')\n",
    "df['capacidade arena'] = df['Arena'].map(map_publico_maximo)\n",
    "\n",
    "# correção manual publico, capacidade e disponibilidade\n",
    "df.loc[(df['Mandante'] == 'Santos') & (df['Visitante'] == 'Portuguesa') & (df['temporada'] == 2008), 'publico pagante'] = 7552 \n",
    "\n",
    "# atribuindo capacidade maxima a venda disponivel para incoerencias que a venda é maior que a capacidade\n",
    "mask_capacidade = df['publico disponivel'] > df['capacidade arena']\n",
    "df.loc[mask_capacidade,'publico disponivel'] = df.loc[mask_capacidade,'capacidade arena']\n",
    "\n",
    "# criadno aproveitamento de cada mandante nas ultimas x rodadas\n",
    "for ano in list(set(df['temporada'])):\n",
    "    df = detox.yield_last_xrounds(df,3,ano)\n",
    "    df = detox.yield_last_xrounds(df,5,ano)\n",
    "\n",
    "df.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Processed\\data_exploratory.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
