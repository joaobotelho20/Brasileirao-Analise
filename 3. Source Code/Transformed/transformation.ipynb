{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3c82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip uninstall spellchecker -y\n",
    "# !pip install pyspellchecker\n",
    "# !pip install unidecode\n",
    "# !pip install scikit-learn  # For cosine_similarity and numpy (it's a dependency)\n",
    "# !pip install sentence-transformers\n",
    "# !pip install pandas\n",
    "# !pip install ipywidgets\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datadetox as detox\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09036e",
   "metadata": {},
   "source": [
    "Leitura e padronização de colunas de chaves primarias para concatenação de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a17ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Já é datetime64, mantido como está.\n",
      "DataFrame 1: Convertendo padrão com '/'\n",
      "DataFrame 2: Convertendo padrão com '/'\n",
      "DataFrame 3: Convertendo padrão com '/'\n",
      "DataFrame 4: Convertendo padrão ISO com '-'\n",
      "DataFrame 5: Já é datetime64, mantido como está.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path = r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed'\n",
    "\n",
    "#Games \n",
    "df_list = []\n",
    "for i in range(1, 7):\n",
    "    df = pd.read_excel(path + f'\\\\0{i}_games.xlsx')\n",
    "    df_list.append(df)\n",
    "\n",
    "#fitragem série B comjunto 5\n",
    "df_list[4] = df_list[4][df_list[4]['Série']=='A']\n",
    "\n",
    "# mapeamento_colunas chave primária\n",
    "mapeamento_colunas = {  'data': 'Data','Date': 'Data','data_partida': 'Data',\n",
    "                        'time_mandante': 'Mandante','mandante': 'Mandante','Home': 'Mandante',\n",
    "                        'time_visitante': 'Visitante','visitante': 'Visitante','Away': 'Visitante'}\n",
    "    \n",
    "\n",
    "df_list = [df.rename(columns=mapeamento_colunas) for df in df_list]\n",
    "\n",
    "df_list = detox.padronizar_datas(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f798d",
   "metadata": {},
   "source": [
    "Unir todos os DFs com agrupamento por colunas, Data, Mandante e Visitante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c16a3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapear cluber qeu o filtro BERT nao resolve (manualmente)\n",
    "clubes_map_inicial = {  \"America-RN\":\"América Natal\",\"América-RN\":\"América Natal\",\"América rn\":\"América Natal\",\n",
    "                        \"Joinvile\":\"Joinville\",\n",
    "                        \"Atlético pr\":\"Athlético-PR\",\"Atlético-PR\":\"Athlético-PR\", \n",
    "                        \"Grêmio Prudente\":\"Barueri\",\"Grêmio prudente\":\"Barueri\",\"Gremio Prudente\":\"Barueri\"}\n",
    "\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_map_inicial)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_map_inicial)\n",
    "\n",
    "# listar clubes Mandantes e visitantes, para agrupar ortograficamente\n",
    "clubes_unicos = []\n",
    "for df in df_list:\n",
    "    unicos_por_bd = pd.unique(np.concatenate([df['Mandante'].values, df['Visitante'].values])).tolist()\n",
    "    clubes_unicos = list(set(clubes_unicos) | set(unicos_por_bd))\n",
    "\n",
    "clubes_value_dict = [   \"América Mineiro\", \"América Natal\", \"Athletico Paranaense\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Avaí\", \"Bahia\", \n",
    "                        \"Barueri\", \"Botafogo\", \"Red Bull Bragantino\", \"Brasiliense\", \"Ceará\", \n",
    "                        \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"CSA\", \"Cuiabá\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \n",
    "                        \"Fortaleza\",\"Guarani\", \"Goiás\", \"Grêmio\", \"Grêmio Prudente\", \"Internacional\", \"Ipatinga\", \"Joinville\", \"Juventude\",\"Mirassol\", \"Náutico\", \n",
    "                        \"Palmeiras\", \"Paraná\", \"Paysandu\", \"Ponte Preta\", \"Portuguesa\", \"Santa Cruz\", \"Santo André\", \"Santos\", \"São Caetano\", \"São Paulo\", \n",
    "                        \"Sport Recife\", \"Vasco da Gama\", \"Vitória\"]\n",
    "\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "clubes_corrigidos = detox.corrigir_times_semanticamente(clubes_unicos, clubes_value_dict,modelo)\n",
    "clubes_dict = detox.gerar_dicionario_mapeamento(clubes_corrigidos, limite=0.0)\n",
    "\n",
    "# corrigindo e agrupando clubes em todos os dataframes\n",
    "for df in df_list:\n",
    "    df['Mandante'] = df['Mandante'].replace(clubes_dict)\n",
    "    df['Visitante'] = df['Visitante'].replace(clubes_dict)\n",
    "\n",
    "# unindo todos os dfs com merge on=['Data','Mandante','Visitante']\n",
    "df_merged = pd.DataFrame(columns=['Data','Mandante','Visitante'])\n",
    "for i,df in enumerate(df_list):\n",
    "    df_merged = pd.merge(df_merged, df, how='outer', on=['Data','Mandante','Visitante'],suffixes=('', f'_{i}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9a0b8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "import datetime as dt\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Criar edições dos campeonatos visto que 2020 foi ate 2021\n",
    "mask = (df['Data'] > dt.datetime(2020, 8, 1)) & (df['Data'] < dt.datetime(2021, 2, 28))\n",
    "df.loc[mask, 'edition'] = 2020\n",
    "df.loc[~mask, 'edition'] = df.loc[~mask, 'Data'].dt.year\n",
    "\n",
    "df.sort_values(by=['Mandante', 'Visitante','edition','Data'], ascending=[True, True, True, True], inplace=True)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dcf1175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_group = df_mesclado.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13184\\2427877954.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(detox.mesclar_linhas_sem_conflito)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "# Agrupar e aplicar a função\n",
    "df_ajustado = df.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(detox.ajustar_datas)\n",
    "\n",
    "# Aplica o agrupamento e mescla as linhas sem conflito\n",
    "df_mesclado = (\n",
    "    df_ajustado.groupby(['Data', 'Mandante', 'Visitante', 'edition'], group_keys=False)\n",
    "      .apply(detox.mesclar_linhas_sem_conflito)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "df_mesclado = df_mesclado[df_mesclado['edition']<2024]\n",
    "\n",
    "df_group = df_mesclado.groupby(['Mandante', 'Visitante', 'edition'], group_keys=False).apply(\n",
    "    lambda group: detox.ajustar_datas_semdiff(group,keep=True))\n",
    "\n",
    "df_mesclado2 = (\n",
    "    df_group.groupby(['Data', 'Mandante', 'Visitante', 'edition'], group_keys=False)\n",
    "      .apply(detox.mesclar_linhas_sem_conflito)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "df_mesclado2.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Agrupamento_unico.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2b352",
   "metadata": {},
   "source": [
    "Garantindo partidas por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "340f62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edições com número desigual de partidas por time: edition\n",
      "2016    2\n",
      "Name: n_partidas, dtype: int64\n",
      "Edições com número desigual de partidas por time: edition\n",
      "2016    2\n",
      "Name: n_partidas, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "importlib.reload(detox)\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Agrupamento_unico.xlsx')\n",
    "\n",
    "#ajustando sao paulo e sao caetano jogo interrompido\n",
    "df.drop(1007, inplace=True)\n",
    "\n",
    "# ajustando jogo do flamengo\n",
    "df.loc[2835, 'Data'] = pd.to_datetime('2009-11-07')\n",
    "df.drop(2834, inplace=True)\n",
    "\n",
    "# ajustando jogo do BOTAFOGO\n",
    "df.loc[1969, 'Data'] = pd.to_datetime('2009-07-29')\n",
    "df.drop(1968, inplace=True)\n",
    "\n",
    "# ajustando jogo da chapecoense\n",
    "df.drop(5753, inplace=True)\n",
    "\n",
    "#2005\n",
    "df.drop([1137,1137,1207,1231,1257,1284,1307,1310,1328,1341,1375,1379], inplace=True)\n",
    "df.loc[1138, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1208, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1232, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1258, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1285, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1308, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1311, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1329, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1342, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1376, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "df.loc[1380, 'Data'] = pd.to_datetime('2009-10-19')\n",
    "\n",
    "#2007 \n",
    "df.drop([1970,1971], inplace=True)\n",
    "\n",
    "\n",
    "detox.verifica_partidas_edi(df,'edition','Mandante')\n",
    "detox.verifica_partidas_edi(df,'edition','Visitante')\n",
    "\n",
    "df.to_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Num_partidas.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3af196",
   "metadata": {},
   "source": [
    "Meslclando Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49ebcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed\\Num_partidas.xlsx')\n",
    "\n",
    "gols_mandante = [\"gols_mandante\",\"mandante_Placar\",\"Mandante Placar\",\"mandante_Placar_3\",\"Gol Mandante\",\"placar_mandante\"]\n",
    "gols_visitante = [\"gols_visitante\",\"visitante_Placar\",\"Visitante Placar\",\"visitante_Placar_3\",\"Gol Visitante\",\"placar_visitante\"]\n",
    "colunas_hora = [\"Horário\", \"hora\", \"hora_3\", \"Hora\", \"hora_partida\"]\n",
    "\n",
    "for col in colunas_hora:\n",
    "    df[col] = df[col].str.replace(r'h', ':', regex=True)\n",
    "    #display(df[col].str.match(r'^\\d{2}:\\d{2}$').value_counts())\n",
    "    df[col] = pd.to_datetime(df[col], format='%H:%M')\n",
    "\n",
    "df[gols_mandante].nunique(axis=1,dropna=True).value_counts()\n",
    "df[gols_visitante].nunique(axis=1,dropna=True).value_counts()\n",
    "df[colunas_hora].nunique(axis=1,dropna=True).value_counts()\n",
    "\n",
    "df['gols_mandante_moda'] = df[gols_mandante].mode(axis=1).iloc[:, 0]\n",
    "df['gols_visitante_moda'] = df[gols_visitante].mode(axis=1).iloc[:, 0]\n",
    "df['horario'] = df[colunas_hora].mode(axis=1).iloc[:, 0]\n",
    "df.drop(columns=gols_mandante+gols_visitante+colunas_hora, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d697b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(detox)\n",
    "\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=1,div=15))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=2,div=15))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=3,div=15))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=4,div=15))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=5,div=30))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=6,div=30))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=7,div=30))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=8,div=30))\n",
    "df['horario'] = df['horario'].apply(lambda x: detox.arredondar_quase_15min(x,min=9,div=30))\n",
    "df.loc[2191, 'horario'] = pd.to_datetime('2009-10-19 19:00') #horario meio noite\n",
    "df['horario'] = df['horario'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f7c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(detox)\n",
    "arenas_col = ['arena', 'Arena', 'arena_3', 'Estádio', 'estadio']\n",
    "\n",
    "# df[gols_mandante].nunique(axis=1,dropna=True).value_counts()\n",
    "# df['Arenas'] = df[arenas_col].mode(axis=1).iloc[:, 0]\n",
    "\n",
    "for col in arenas_col:\n",
    "    df[col] = df[col].apply(detox.normalizar_texto)\n",
    "    df[col] = df[col].str.replace(r'\\bestadio\\b', '', regex=True).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\(\\*pf\\)', '', regex=True).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\*\\(pf\\)', '', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc0091eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arena_moda\n",
       "maracana                            630\n",
       "mineirao                            459\n",
       "morumbi                             413\n",
       "beira-rio                           369\n",
       "ligga arena                         359\n",
       "vila belmiro                        357\n",
       "nilton santos                       299\n",
       "couto pereira                       297\n",
       "serra dourada                       295\n",
       "pacaembu                            278\n",
       "independencia                       274\n",
       "allianz parque                      262\n",
       "sao januario                        261\n",
       "castelao                            251\n",
       "orlando scarpelli                   219\n",
       "neo quimica arena                   185\n",
       "barradao                            183\n",
       "arena do gremio                     183\n",
       "ilha do retiro                      181\n",
       "moises lucarelli                    179\n",
       "olimpico                            172\n",
       "fonte nova                          155\n",
       "alfredo jaconi                      146\n",
       "ressacada                           134\n",
       "arena conda                         132\n",
       "raulino de oliveira                 100\n",
       "anacleto campanella                  88\n",
       "heriberto hulse                      83\n",
       "nabi abi chedid                      76\n",
       "aflitos                              75\n",
       "arena do jacare                      72\n",
       "brinco de ouro                       67\n",
       "arena pantanal                       66\n",
       "mangueirao                           66\n",
       "pinheirao                            65\n",
       "pituacu                              65\n",
       "caninde                              65\n",
       "vila capanema                        65\n",
       "luso brasileiro                      62\n",
       "serrinha                             57\n",
       "arena barueri                        47\n",
       "arena pernambuco                     47\n",
       "mane garrincha                       45\n",
       "antonio accioly                      44\n",
       "presidente vargas                    42\n",
       "arruda                               41\n",
       "ipatingao                            34\n",
       "prudentao                            28\n",
       "olimpico pedro ludovico teixeira     25\n",
       "arena joinville                      22\n",
       "parque do sabia                      21\n",
       "machadao                             19\n",
       "boca do jacare                       19\n",
       "caio martins                         19\n",
       "centenario                           19\n",
       "bruno jose daniel                    18\n",
       "rei pele                             18\n",
       "giulite coutinho                     17\n",
       "claudio moacyr de azevedo            15\n",
       "fonte luminosa                       10\n",
       "kleber andrade                       10\n",
       "helenao                               9\n",
       "arena mrv                             9\n",
       "estadio do vale                       8\n",
       "willie davids                         8\n",
       "teixeirao                             8\n",
       "vail chaves                           7\n",
       "estadio do cafe                       6\n",
       "joia da princesa                      6\n",
       "arena amazonia                        5\n",
       "colosso da lagoa                      3\n",
       "do melao                              3\n",
       "morenao                               3\n",
       "novelli junior                        3\n",
       "bezerrao                              2\n",
       "arena batistao                        2\n",
       "olimpico regional                     2\n",
       "bento freitas                         2\n",
       "curuzu                                2\n",
       "arena das dunas                       2\n",
       "engenheiro araripe                    2\n",
       "juscelino kubitscheck                 2\n",
       "limeirao                              1\n",
       "vila olimpica                         1\n",
       "lacerdao                              1\n",
       "antonio guimaraes                     1\n",
       "1o de maio                            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lista fornecida pelo chat gpt\n",
    "mapeamento_estadios = {\n",
    "    \"olimpico engenhao\": \"nilton santos\",\n",
    "    \"engenhao\": \"nilton santos\",\n",
    "    \"arena corinthians\": \"neo quimica arena\",\n",
    "    \"neo quimica arena\": \"neo quimica arena\",\n",
    "    \"municipal paulo machado de carvalho\": \"pacaembu\",\n",
    "    \"urbano caldeira\": \"vila belmiro\",\n",
    "    \"jose pinheiro borda\": \"beira-rio\",\n",
    "    \"beira rio\": \"beira-rio\",\n",
    "    \"arena castelao\": \"castelao\",\n",
    "    \"placido castelo\": \"castelao\",\n",
    "    \"castelao de sao luis\": \"castelao\",\n",
    "    \"parque antartica\": \"allianz parque\",\n",
    "    \"palestra italia\": \"allianz parque\",\n",
    "    \"itaipava arena fonte nova\": \"fonte nova\",\n",
    "    \"arena fonte nova\": \"fonte nova\",\n",
    "    \"da serrinha\": \"serrinha\",\n",
    "    \"adelmar da costa carvalho\": \"ilha do retiro\",\n",
    "    \"raimundo sampaio\": \"independencia\",\n",
    "    \"do governo do estado de goias (serra dourada)\": \"serra dourada\",\n",
    "    \"nabizao\": \"nabi abi chedid\",\n",
    "    \"kyocera arena\": \"ligga arena\",\n",
    "    \"arena da baixada\": \"ligga arena\",\n",
    "    \"joaquim americo guimaraes\": \"ligga arena\",\n",
    "    \"municipal general raulino de oliveira\": \"raulino de oliveira\",\n",
    "    \"haile pinheiro - serrinha\" : \"serrinha\",\n",
    "    \"do vale\": \"estadio do vale\",\n",
    "    \"claudio moacyr\": \"claudio moacyr de azevedo\",\n",
    "    \"municipal parque do sabia\": \"parque do sabia\",\n",
    "    \"moacyrzao\": \"claudio moacyr de azevedo\",\n",
    "    \"do cafe\": \"estadio do cafe\",\n",
    "    \"alberto oliveira\": \"joia da princesa\",\n",
    "    \"vasco da gama\": \"sao januario\",\n",
    "    \"doutor adhemar de barros\": \"fonte luminosa\",\n",
    "    \"santa cruz\": \"arruda\",\n",
    "    \"benedito teixeira\": \"teixeirao\",\n",
    "    \"melao\": \"estadio do melao\",\n",
    "    \"pres vargas\": \"presidente vargas\",\n",
    "    \"mario helenio\": \"helenao\",\n",
    "    \"batistao\": \"arena batistao\",\n",
    "    \"romildao\": \"vail chaves\",\n",
    "    \"wilson de barros\": \"vail chaves\",\n",
    "    \"eduardo jose farah\": \"prudentao\",\n",
    "    \"g coutinho\": \"giulite coutinho\",\n",
    "    \"bruno j daniel \": \"bruno jose daniel\",\n",
    "    \"mj jose levi sobrinho\": \"limeirao\",\n",
    "    \"pedro pedrossian\": \"morenao\",\n",
    "    \"vivaldo lima\": \"arena da amazonia\",\n",
    "    \"edson passos\": \"giulite coutinho\",\n",
    "    \"municipal juiz de fora\": \"helenao\",\n",
    "    \"a campanella\": \"anacleto campanella\",\n",
    "    \"bruno j.daniel\": \"bruno jose daniel\",\n",
    "    \"bruno j daniel\": \"bruno jose daniel\",\n",
    "    \"luiz lacerda\": \"lacerdao\",\n",
    "    \"r de oliveira\": \"raulino de oliveira\",\n",
    "    \"serejao\": \"boca do jacare\",\n",
    "    \"a.campanella\": \"anacleto campanella\",\n",
    "    \"papa joao paulo ii\": \"vail chaves\",\n",
    "    \"papa j.paulo ii\": \"vail chaves\",\n",
    "    \"municipal juscelino kubitschek\": \"juscelino kubitscheck\",\n",
    "    \"juiz de fora\":\"helenao\",\n",
    "    \"romildo ferreira\": \"vail chaves\",\n",
    "    \"paulo constantino\": \"prudentao\",\n",
    "    \"joaquim henrique nogueira-arena do jacare\": \"arena do jacare\",\n",
    "    \"luso-brasileiro\": \"luso brasileiro\",\n",
    "    \"arena brb mane garrincha\": \"mane garrincha\",\n",
    "    \"bruno josé daniel\": \"bruno jose daniel\",\n",
    "    \"de pituacu\": \"pituacu\",\n",
    "    \"texeirao\": \"teixeirao\",\n",
    "    \"arena de pernambuco\": \"arena pernambuco\",\n",
    "    \"arena da amazonia\":\"arena amazonia\",\n",
    "    \"nacional de brasilia\": \"mane garrincha\",\n",
    "    \"durival de brito\": \"vila capanema\",}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for arena in arenas_col:\n",
    "    df[arena] = df[arena].replace(mapeamento_estadios)\n",
    "\n",
    "df['Arenas_iguais'] = df[arenas_col].nunique(axis=1, dropna=True) == 1\n",
    "#display(df[arenas_col+['Arenas_iguais']])\n",
    "\n",
    "# indicando a moda maior que 2\n",
    "df['Arena_moda'] = df[arenas_col].mode(axis=1, dropna=True).iloc[:, 0]\n",
    "#df['Arena_moda'] = df['Arena_moda'].apply(lambda x: x if x > 2 else None)\n",
    "\n",
    "mask = df['Arenas_iguais'] == False\n",
    "#display(df[mask][arenas_col])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(df['Arena_moda'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
