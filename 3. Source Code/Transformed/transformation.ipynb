{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea3c82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip install -U torch transformers accelerate sentence-transformers\n",
    "# !pip uninstall spellchecker -y\n",
    "# !pip install pyspellchecker\n",
    "# !pip install unidecode\n",
    "# !pip install scikit-learn  # For cosine_similarity and numpy (it's a dependency)\n",
    "# !pip install sentence-transformers\n",
    "# !pip install pandas\n",
    "\n",
    "import re\n",
    "import unidecode\n",
    "from spellchecker import SpellChecker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09036e",
   "metadata": {},
   "source": [
    "Leitura e padronização de colunas de chaves primarias para concatenação de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a17ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 1: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/03/2003' '29/03/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 2: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/03/2003' '29/03/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 3: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/3/2003' '29/3/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 4: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2012-05-19T00:00:00.000000000' '2012-05-19T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 5: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 6: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['2012-05-20' '2012-05-20']\n",
      "Tem duplicatas? False\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path = r'C:\\Users\\USER\\Desktop\\GitHub\\Brasileirao-Analise\\1. Data\\Transformed'\n",
    "\n",
    "#Games \n",
    "df_list = []\n",
    "for i in range(1, 8):\n",
    "    df = pd.read_excel(path + f'\\\\0{i}_games.xlsx')\n",
    "    df_list.append(df)\n",
    "\n",
    "# db_id = 3  # 0 - 6\n",
    "# display(df_list[db_id].describe())\n",
    "# display(df_list[db_id].head(-3))\n",
    "# display(df_list[db_id].info())\n",
    "\n",
    "#fitragem série B comjumto 7\n",
    "df_list[6] = df_list[6][df_list[6]['Série']=='A']\n",
    "\n",
    "# mapeamento_colunas chave primária\n",
    "mapeamento_colunas = {\n",
    "    'data': 'Data',\n",
    "    'Date': 'Data',\n",
    "    'data_partida': 'Data',\n",
    "    'time_mandante': 'Mandante',\n",
    "    'mandante': 'Mandante',\n",
    "    'Home': 'Mandante',\n",
    "    'time_visitante': 'Visitante',\n",
    "    'visitante': 'Visitante',\n",
    "    'Away': 'Visitante',\n",
    "}\n",
    "df_list = [df.rename(columns=mapeamento_colunas) for df in df_list]\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    # # Para strings em formato brasileiro (DD/MM/AAAA)\n",
    "    # df_list[i]['Data'] = pd.to_datetime(df_list[i]['Data'], format='%d/%m/%Y', errors='coerce')\n",
    "    # # Mantenha apenas a data, removendo a parte do tempo\n",
    "    # df_list[i]['Data'] = pd.to_datetime(df_list[i]['Data']).dt.date\n",
    "    print(f\"DataFrame {i}: Tipo da coluna 'Data' = {df['Data'].dtype}\")\n",
    "    print(f\"Primeiros valores: {df['Data'].head(2).values}\")\n",
    "    print(f\"Tem duplicatas? {df.duplicated(subset=['Data', 'Mandante', 'Visitante']).any()}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ca95df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 0:\n",
      "  Tipo da coluna 'Data': datetime64[ns]\n",
      "  Exemplo de valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 1:\n",
      "  Tipo da coluna 'Data': object\n",
      "  Exemplo de valores: ['29/03/2003' '29/03/2003']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 2:\n",
      "  Tipo da coluna 'Data': object\n",
      "  Exemplo de valores: ['29/03/2003' '29/03/2003']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 3:\n",
      "  Tipo da coluna 'Data': object\n",
      "  Exemplo de valores: ['29/3/2003' '29/3/2003']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 4:\n",
      "  Tipo da coluna 'Data': datetime64[ns]\n",
      "  Exemplo de valores: ['2012-05-19T00:00:00.000000000' '2012-05-19T00:00:00.000000000']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 5:\n",
      "  Tipo da coluna 'Data': datetime64[ns]\n",
      "  Exemplo de valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "  Valores nulos: 0\n",
      "\n",
      "DataFrame 6:\n",
      "  Tipo da coluna 'Data': object\n",
      "  Exemplo de valores: ['2012-05-20' '2012-05-20']\n",
      "  Valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "def verificar_padrao_datas(df, coluna_data='Data'):\n",
    "    \"\"\"\n",
    "    Verifica se todas as datas na coluna seguem o mesmo padrão.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame contendo a coluna de datas\n",
    "        coluna_data: Nome da coluna que contém as datas\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicionário com informações sobre os padrões encontrados\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Pular se a coluna já for datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[coluna_data]):\n",
    "        return {\n",
    "            'padrao_unico': True,\n",
    "            'tipo': 'datetime64',\n",
    "            'padroes': {'datetime64': len(df)}\n",
    "        }\n",
    "    \n",
    "    # Função para detectar o padrão da data\n",
    "    def detectar_padrao(data_str):\n",
    "        if pd.isna(data_str):\n",
    "            return 'NaN'\n",
    "            \n",
    "        # Remover espaços\n",
    "        data_str = str(data_str).strip()\n",
    "        \n",
    "        # Padrões comuns\n",
    "        padroes = {\n",
    "            r'^\\d{2}/\\d{2}/\\d{4}$': 'DD/MM/YYYY',\n",
    "            r'^\\d{1,2}/\\d{1,2}/\\d{4}$': 'D/M/YYYY',\n",
    "            r'^\\d{4}-\\d{2}-\\d{2}$': 'YYYY-MM-DD',\n",
    "            r'^\\d{2}-\\d{2}-\\d{4}$': 'DD-MM-YYYY',\n",
    "            r'^\\d{1,2}-\\d{1,2}-\\d{4}$': 'D-M-YYYY',\n",
    "            r'^\\d{2}\\.\\d{2}\\.\\d{4}$': 'DD.MM.YYYY',\n",
    "            r'^\\d{1,2}\\.\\d{1,2}\\.\\d{4}$': 'D.M.YYYY',\n",
    "            r'^\\d{4}/\\d{2}/\\d{2}$': 'YYYY/MM/DD'\n",
    "        }\n",
    "        \n",
    "        for regex, nome_padrao in padroes.items():\n",
    "            if re.match(regex, data_str):\n",
    "                return nome_padrao\n",
    "                \n",
    "        return 'desconhecido'\n",
    "    \n",
    "    # Detectar o padrão de cada data\n",
    "    padroes = df[coluna_data].apply(detectar_padrao)\n",
    "    \n",
    "    # Contar os padrões\n",
    "    contagem_padroes = Counter(padroes)\n",
    "    \n",
    "    # Verificar se há apenas um padrão (excluindo NaN)\n",
    "    padroes_sem_nan = {k: v for k, v in contagem_padroes.items() if k != 'NaN'}\n",
    "    padrao_unico = len(padroes_sem_nan) == 1\n",
    "    \n",
    "    # Recuperar exemplos de cada padrão\n",
    "    exemplos = {}\n",
    "    for padrao in contagem_padroes.keys():\n",
    "        if padrao != 'NaN':\n",
    "            exemplos[padrao] = df.loc[padroes == padrao, coluna_data].iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'padrao_unico': padrao_unico,\n",
    "        'padroes': dict(contagem_padroes),\n",
    "        'exemplos': exemplos,\n",
    "        'padrao_principal': padroes.value_counts().index[0] if not padroes.empty else None\n",
    "    }\n",
    "\n",
    "\n",
    "def padronizar_datas(df_list):\n",
    "    \"\"\"\n",
    "    Padroniza todas as colunas de data nos DataFrames para datetime64[ns]\n",
    "    \n",
    "    Args:\n",
    "        df_list: Lista de DataFrames com coluna 'Data'\n",
    "        \n",
    "    Returns:\n",
    "        Lista de DataFrames com as datas padronizadas\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        # Pular se já for datetime64\n",
    "        if pd.api.types.is_datetime64_any_dtype(df['Data']):\n",
    "            print(f\"DataFrame {i}: Já é datetime64, mantido como está.\")\n",
    "            continue\n",
    "\n",
    "        # Verificar o tipo de padrão predominante\n",
    "        if all(df['Data'].str.contains('/', regex=False)):\n",
    "            # Padrões DD/MM/YYYY ou D/M/YYYY (com separador '/')\n",
    "            print(f\"DataFrame {i}: Convertendo padrão com '/'\")\n",
    "            # Usar dayfirst=True para formatos DD/MM/YYYY e D/M/YYYY\n",
    "            df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')\n",
    "        \n",
    "        elif all(df['Data'].str.contains('-', regex=False)):\n",
    "            # Padrão YYYY-MM-DD (ISO)\n",
    "            print(f\"DataFrame {i}: Convertendo padrão ISO com '-'\")\n",
    "            df['Data'] = pd.to_datetime(df['Data'], errors='coerce')\n",
    "            \n",
    "        else:\n",
    "            # Tentar formato misto para casos mais complexos\n",
    "            print(f\"DataFrame {i}: Tentando conversão com formato misto\")\n",
    "            df['Data'] = pd.to_datetime(df['Data'], format='mixed', dayfirst=True, errors='coerce')\n",
    "        \n",
    "        # Verificar se houve valores que não puderam ser convertidos\n",
    "        num_nulos = df['Data'].isna().sum()\n",
    "        if num_nulos > 0:\n",
    "            print(f\"  Atenção: {num_nulos} valores não puderam ser convertidos\")\n",
    "    \n",
    "    return df_list\n",
    "\n",
    "# # Exemplo de uso:\n",
    "# for i, df in enumerate(df_list):\n",
    "#     resultado = verificar_padrao_datas(df)\n",
    "#     print(f\"DataFrame {i}:\")\n",
    "#     print(f\"  Padrão único: {resultado['padrao_unico']}\")\n",
    "#     print(f\"  Padrões encontrados: {resultado['padroes']}\")\n",
    "#     if 'exemplos' in resultado:\n",
    "#         print(f\"  Exemplos: {resultado['exemplos']}\")\n",
    "#     #print(f\"  Padrão principal: {resultado['padrao_principal']}\")\n",
    "#     print(\"---\")\n",
    "\n",
    "# Verificar os resultados\n",
    "for i, df in enumerate(df_list):\n",
    "    print(f\"\\nDataFrame {i}:\")\n",
    "    print(f\"  Tipo da coluna 'Data': {df['Data'].dtype}\")\n",
    "    print(f\"  Exemplo de valores: {df['Data'].head(2).values}\")\n",
    "    print(f\"  Valores nulos: {df['Data'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14d20e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 1: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/03/2003' '29/03/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 2: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/03/2003' '29/03/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 3: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['29/3/2003' '29/3/2003']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 4: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2012-05-19T00:00:00.000000000' '2012-05-19T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 5: Tipo da coluna 'Data' = datetime64[ns]\n",
      "Primeiros valores: ['2003-03-29T00:00:00.000000000' '2003-03-29T00:00:00.000000000']\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 6: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: ['2012-05-20' '2012-05-20']\n",
      "Tem duplicatas? False\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(df_list):\n",
    "    # # Para strings em formato brasileiro (DD/MM/AAAA)\n",
    "    # df_list[i]['Data'] = pd.to_datetime(df_list[i]['Data'], format='%d/%m/%Y', errors='coerce')\n",
    "    # # Mantenha apenas a data, removendo a parte do tempo\n",
    "    # df_list[i]['Data'] = pd.to_datetime(df_list[i]['Data']).dt.date\n",
    "    print(f\"DataFrame {i}: Tipo da coluna 'Data' = {df['Data'].dtype}\")\n",
    "    print(f\"Primeiros valores: {df['Data'].head(2).values}\")\n",
    "    print(f\"Tem duplicatas? {df.duplicated(subset=['Data', 'Mandante', 'Visitante']).any()}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "mandante_list = []\n",
    "visitante_list = []\n",
    "for i in range(len(df_list)):\n",
    "    mandante_list += df_list[i]['Mandante'].unique().tolist()\n",
    "    visitante_list += df_list[i]['Visitante'].unique().tolist()\n",
    "\n",
    "visitante_list_unique = list(set(visitante_list))\n",
    "mandante_list_unique = list(set(mandante_list))\n",
    "clubes_serie_a_2003_2025 = [\"América Mineiro\", \"América Natal\", \"Athletico Paranaense\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Avaí\", \"Bahia\", \n",
    "                            \"Barueri\", \"Botafogo\", \"Red Bull Bragantino\", \"Brasiliense\", \"Ceará\", \n",
    "                            \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"CSA\", \"Cuiabá\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \n",
    "                            \"Fortaleza\",\"Guarani\", \"Goiás\", \"Grêmio\", \"Grêmio Prudente\", \"Internacional\", \"Ipatinga\", \"Joinville\", \"Juventude\",\"Mirassol\", \"Náutico\", \n",
    "                            \"Palmeiras\", \"Paraná\", \"Paysandu\", \"Ponte Preta\", \"Portuguesa\", \"Santa Cruz\", \"Santo André\", \"Santos\", \"São Caetano\", \"São Paulo\", \n",
    "                            \"Sport Recife\", \"Vasco da Gama\", \"Vitória\"]\n",
    "\n",
    "\n",
    "def corrigir_times_semanticamente(lista_times, lista_referencia, modelo=None):\n",
    "    \"\"\"\n",
    "    Compara semanticamente os nomes de times com uma lista de referência.\n",
    "    \n",
    "    Parâmetros:\n",
    "        lista_times (list): Lista com nomes possivelmente errados ou alternativos.\n",
    "        lista_referencia (list): Lista com nomes corretos (padrão).\n",
    "        modelo: Um modelo SentenceTransformer. Se None, será carregado 'all-MiniLM-L6-v2'.\n",
    "    \n",
    "    Retorna:\n",
    "        List[Tuple[str, str, float]]: Lista com (nome_original, nome_corrigido, similaridade).\n",
    "    \"\"\"\n",
    "    if modelo is None:\n",
    "        modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    emb_ref = modelo.encode(lista_referencia)\n",
    "    resultados = []\n",
    "\n",
    "    for time in lista_times:\n",
    "        emb_time = modelo.encode([time])\n",
    "        sims = cosine_similarity(emb_time, emb_ref)[0]\n",
    "        idx_mais_similar = np.argmax(sims)\n",
    "        nome_corrigido = lista_referencia[idx_mais_similar]\n",
    "        similaridade = sims[idx_mais_similar]\n",
    "        resultados.append((time, nome_corrigido, round(similaridade, 1)))\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def exibir_times_agrupados_por_referencia(resultados, lista_referencia, limite=0.5, limite_sup=1):\n",
    "    \"\"\"\n",
    "    Exibe os times agrupados por nome de referência com suas similaridades.\n",
    "    \n",
    "    Parâmetros:\n",
    "        resultados: Saída da função corrigir_times_semanticamente.\n",
    "        lista_referencia: Lista com os nomes corretos.\n",
    "        limite: Similaridade mínima para considerar um match (default=0.5).\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    agrupados = defaultdict(list)\n",
    "\n",
    "    # Agrupar por nome corrigido\n",
    "    for original, corrigido, score in resultados:\n",
    "        if score >= limite and score < limite_sup:\n",
    "            agrupados[corrigido].append(f\"{original} ({score})\")\n",
    "\n",
    "    # Exibir os nomes da lista de referência em ordem\n",
    "    for nome in sorted(lista_referencia):\n",
    "        similares = agrupados.get(nome, [])\n",
    "        if similares:\n",
    "            print(f\"{nome}: {', '.join(similares)}\")\n",
    "\n",
    "# Criar dicionário a partir dos resultados da correção semântica\n",
    "def gerar_dicionario_mapeamento(resultados, limite=0.5):\n",
    "    \"\"\"\n",
    "    Gera um dicionário que mapeia nomes originais para nomes corrigidos, com base na similaridade.\n",
    "    \n",
    "    Parâmetros:\n",
    "        resultados (list): Saída da função corrigir_times_semanticamente.\n",
    "        limite (float): Similaridade mínima para considerar um match.\n",
    "        \n",
    "    Retorna:\n",
    "        dict: Mapeamento {nome_original: nome_corrigido}\n",
    "    \"\"\"\n",
    "    mapeamento = {\n",
    "        original: corrigido \n",
    "        for original, corrigido, score in resultados \n",
    "        if score >= limite\n",
    "    }\n",
    "    return mapeamento\n",
    "\n",
    "#resultados = corrigir_times_semanticamente(visitante, clubes_serie_a_2003_2025)\n",
    "\n",
    "# for i, (original, corrigido, score) in enumerate(resultados):\n",
    "#   if score < 1:\n",
    "#     print(f\"{i}:{original} → {corrigido} (similaridade: {score})\")\n",
    "\n",
    "# Mapeamento pois esses times não estão na lista de referencia e cruzando com alta similaridade incorreta\n",
    "map_clubes = {\n",
    "    \"America-RN\":\"América Natal\",\n",
    "    \"América-RN\":\"América Natal\",\n",
    "    \"América rn\":\"América Natal\",\n",
    "    \"Joinvile\":\"Joinville\",\n",
    "    \"Atlético pr\":\"Athlético-PR\",  \n",
    "    \"Atlético-PR\":\"Athlético-PR\",\n",
    "    \"Grêmio Prudente\":\"Barueri\",\n",
    "    \"Grêmio prudente\":\"Barueri\",\n",
    "    \"Gremio Prudente\":\"Barueri\"     \n",
    "}\n",
    "\n",
    "visitante_map,mandante_map = list(map(lambda x: map_clubes.get(x, x), visitante_list_unique)),list(map(lambda x: map_clubes.get(x, x), mandante_list_unique))\n",
    "\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "resultados = corrigir_times_semanticamente(visitante_map, clubes_serie_a_2003_2025, modelo)\n",
    "visitante_map = gerar_dicionario_mapeamento(resultados, limite=0.0)\n",
    "# print(\"Visitantes que não tem similaridade 100% com os clubes da série A de 2003 a 2025\\n\")\n",
    "# exibir_times_agrupados_por_referencia(resultados, clubes_serie_a_2003_2025, limite=0.0)\n",
    "\n",
    "resultados = corrigir_times_semanticamente(mandante_map, clubes_serie_a_2003_2025, modelo)\n",
    "mandante_map = gerar_dicionario_mapeamento(resultados, limite=0.0)\n",
    "# print(\"\\nMandantes que não tem similaridade 100% com os clubes da série A de 2003 a 2025\\n\")\n",
    "# exibir_times_agrupados_por_referencia(resultados, clubes_serie_a_2003_2025, limite=0.0)\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i]['Mandante'] = df_list[i]['Mandante'].map(mandante_map)\n",
    "    df_list[i]['Visitante'] = df_list[i]['Visitante'].map(visitante_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicionar coluna para cada df identificando a origem do dataframe\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i]['Origem'] = f'{i+1}'\n",
    "    # db_id = 3  # 0 - 6\n",
    "    #display(df_list[i].describe())\n",
    "    #display(df_list[i].head(-3))\n",
    "    #display(df_list[i].info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2003, 3, 29) datetime.date(2003, 3, 29)]\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 1: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2003, 3, 29) datetime.date(2003, 3, 29)]\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 2: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2003, 3, 29) datetime.date(2003, 3, 29)]\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 3: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2003, 3, 29) datetime.date(2003, 3, 29)]\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 4: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2012, 5, 19) datetime.date(2012, 5, 19)]\n",
      "Tem duplicatas? False\n",
      "---\n",
      "DataFrame 5: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2003, 3, 29) datetime.date(2003, 3, 29)]\n",
      "Tem duplicatas? True\n",
      "---\n",
      "DataFrame 6: Tipo da coluna 'Data' = object\n",
      "Primeiros valores: [datetime.date(2012, 5, 19) datetime.date(2012, 5, 19)]\n",
      "Tem duplicatas? False\n",
      "---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 5 tem 1004 linhas duplicadas!\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_list[0]\n",
    "for i, df_next in enumerate(df_list[1:], 1):\n",
    "    # Verifica se há duplicatas antes do merge\n",
    "    duplicates = df_next.duplicated(subset=['Data', 'Mandante', 'Visitante'], keep=False)\n",
    "    if duplicates.any():\n",
    "        print(f\"DataFrame {i} tem {duplicates.sum()} linhas duplicadas!\")\n",
    "    \n",
    "    # Merge com tratamento para validação \n",
    "    df_merged = pd.merge(\n",
    "        df_merged,\n",
    "        df_next,\n",
    "        on=['Data', 'Mandante', 'Visitante'],\n",
    "        how='outer',\n",
    "        suffixes=(f'_{i-1}', f'_{i}')\n",
    "        # Sem validação, pois pode haver duplicatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11779 entries, 0 to 11778\n",
      "Data columns (total 51 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   Ano_1                           8453 non-null   float64       \n",
      " 1   Data                            11779 non-null  datetime64[ns]\n",
      " 2   rodada                          8453 non-null   float64       \n",
      " 3   estadio                         8442 non-null   object        \n",
      " 4   arbitro                         6743 non-null   object        \n",
      " 5   publico                         6742 non-null   float64       \n",
      " 6   publico_max                     4181 non-null   float64       \n",
      " 7   Mandante                        11453 non-null  object        \n",
      " 8   Visitante                       11448 non-null  object        \n",
      " 9   tecnico_mandante_1              6299 non-null   object        \n",
      " 10  tecnico_visitante_1             6299 non-null   object        \n",
      " 11  colocacao_mandante              6743 non-null   float64       \n",
      " 12  colocacao_visitante             6743 non-null   float64       \n",
      " 13  valor_equipe_titular_mandante   6355 non-null   float64       \n",
      " 14  valor_equipe_titular_visitante  6355 non-null   float64       \n",
      " 15  idade_media_titular_mandante    6353 non-null   float64       \n",
      " 16  idade_media_titular_visitante   6353 non-null   float64       \n",
      " 17  gols_mandante                   8452 non-null   float64       \n",
      " 18  gols_visitante                  8452 non-null   float64       \n",
      " 19  gols_1_tempo_mandante           6732 non-null   float64       \n",
      " 20  gols_1_tempo_visitante          6732 non-null   float64       \n",
      " 21  escanteios_mandante             2087 non-null   float64       \n",
      " 22  escanteios_visitante            2087 non-null   float64       \n",
      " 23  faltas_mandante                 2087 non-null   float64       \n",
      " 24  faltas_visitante                2087 non-null   float64       \n",
      " 25  chutes_bola_parada_mandante     2087 non-null   float64       \n",
      " 26  chutes_bola_parada_visitante    2087 non-null   float64       \n",
      " 27  defesas_mandante                2087 non-null   float64       \n",
      " 28  defesas_visitante               2087 non-null   float64       \n",
      " 29  impedimentos_mandante           2087 non-null   float64       \n",
      " 30  impedimentos_visitante          2087 non-null   float64       \n",
      " 31  chutes_mandante                 2087 non-null   float64       \n",
      " 32  chutes_visitante                2087 non-null   float64       \n",
      " 33  chutes_fora_mandante            2087 non-null   float64       \n",
      " 34  chutes_fora_visitante           2087 non-null   float64       \n",
      " 35  Origem_1                        8453 non-null   object        \n",
      " 36  Ano_2                           8405 non-null   float64       \n",
      " 37  ID                              8405 non-null   float64       \n",
      " 38  rodata                          8405 non-null   float64       \n",
      " 39  hora                            8405 non-null   object        \n",
      " 40  formacao_mandante               3431 non-null   object        \n",
      " 41  formacao_visitante              3431 non-null   object        \n",
      " 42  tecnico_mandante_2              3795 non-null   object        \n",
      " 43  tecnico_visitante_2             3795 non-null   object        \n",
      " 44  vencedor                        8405 non-null   object        \n",
      " 45  arena                           8405 non-null   object        \n",
      " 46  mandante_Placar                 8405 non-null   float64       \n",
      " 47  visitante_Placar                8405 non-null   float64       \n",
      " 48  mandante_Estado                 8405 non-null   object        \n",
      " 49  visitante_Estado                8405 non-null   object        \n",
      " 50  Origem_2                        8405 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(33), object(17)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11779, 51)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df_merged = df_list[0]\n",
    "# for df_next in df_list[1:2]:\n",
    "#     df_merged = pd.merge(\n",
    "#         df_merged,\n",
    "#         df_next,\n",
    "#         on=['Data', 'Mandante', 'Visitante'],  # Suas três colunas chaves\n",
    "#         how='outer',  # Ou outro tipo de join conforme necessidade\n",
    "#         suffixes=(f'_{i}', f'_{i+1}')\n",
    "#         #validate='one_to_one')\n",
    "\n",
    "df_merged = pd.merge(df_list[0], df_list[1], on=['Data', 'Mandante', 'Visitante'], how='outer', suffixes=('_1', '_2'))\n",
    "#df_merged.shape()\n",
    "df_merged.describe()\n",
    "df_merged.info()\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d1560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(df_list[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "43\n",
      "43\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "42\n",
      "42\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "43\n",
      "43\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "36\n",
      "36\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Botafogo', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Internacional', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santos', 'Sport Recife', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Botafogo', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Internacional', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santos', 'Sport Recife', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "38\n",
      "38\n",
      "['América Mineiro', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Barueri', 'Botafogo', 'Brasiliense', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Guarani', 'Internacional', 'Ipatinga', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Paysandu', 'Ponte Preta', 'Portuguesa', 'Santa Cruz', 'Santo André', 'Santos', 'Sport Recife', 'São Caetano', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "36\n",
      "36\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Botafogo', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Internacional', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santos', 'Sport Recife', 'São Paulo', 'Vasco da Gama', 'Vitória']\n",
      "['América Mineiro', 'Athletico Paranaense', 'Atlético Goianiense', 'Atlético Mineiro', 'Avaí', 'Bahia', 'Botafogo', 'CSA', 'Ceará', 'Chapecoense', 'Corinthians', 'Coritiba', 'Criciúma', 'Cruzeiro', 'Cuiabá', 'Figueirense', 'Flamengo', 'Fluminense', 'Fortaleza', 'Goiás', 'Grêmio', 'Internacional', 'Joinville', 'Juventude', 'Náutico', 'Palmeiras', 'Paraná', 'Ponte Preta', 'Portuguesa', 'Red Bull Bragantino', 'Santa Cruz', 'Santos', 'Sport Recife', 'São Paulo', 'Vasco da Gama', 'Vitória']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    print(len(sorted(df_list[i]['Mandante'].dropna().unique())))\n",
    "    print(len(sorted(df_list[i]['Visitante'].dropna().unique())))\n",
    "\n",
    "    print(sorted(df_list[i]['Mandante'].dropna().unique()))\n",
    "    print(sorted(df_list[i]['Visitante'].dropna().unique()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de clubes únicos: 45\n"
     ]
    }
   ],
   "source": [
    "# não esta validado\n",
    "\n",
    "camp_2003 = [\"América Mineiro\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Bahia\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"Flamengo\", \"Fluminense\", \"Fortaleza\", \"Goiás\", \"Grêmio\", \"Guarani\", \"Internacional\", \"Juventude\", \"Palmeiras\", \"Paraná\", \"Ponte Preta\", \"Portuguesa\", \"Santos\", \"São Caetano\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2004 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Botafogo\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Juventude\", \"Palmeiras\", \"Paraná\", \"Ponte Preta\", \"Santos\", \"São Caetano\", \"São Paulo\", \"Vasco da Gama\", \"Vitória\"]\n",
    "camp_2005 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Botafogo\", \"Brasiliense\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Fortaleza\", \"Goiás\", \"Internacional\", \"Juventude\", \"Palmeiras\", \"Paraná\", \"Ponte Preta\", \"Santos\", \"São Caetano\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2006 = [\"Atlético Paranaense\", \"Botafogo\", \"Corinthians\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Fortaleza\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Juventude\", \"Palmeiras\", \"Paraná\", \"Ponte Preta\", \"Santa Cruz\", \"Santos\", \"São Caetano\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2007 = [\"América de Natal\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Botafogo\", \"Corinthians\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Juventude\", \"Náutico\", \"Palmeiras\", \"Paraná\", \"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\"]\n",
    "camp_2008 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Botafogo\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Ipatinga\", \"Náutico\", \"Palmeiras\", \"Portuguesa\", \"Santos\", \"São Paulo\", \"Sport\", \"Vitória\", \"Vasco da Gama\"]\n",
    "camp_2009 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Avaí\", \"Barueri\", \"Botafogo\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Náutico\", \"Palmeiras\", \"Santo André\", \"Santos\", \"São Paulo\", \"Sport\", \"Vitória\"]\n",
    "camp_2010 = [\"Atlético Goianiense\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Avaí\", \"Botafogo\", \"Ceará\", \"Corinthians\", \"Cruzeiro\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Guarani\", \"Internacional\", \"Palmeiras\", \"Prudente\", \"Santos\", \"São Paulo\", \"Vitória\", \"Vasco da Gama\"]\n",
    "camp_2011 = [\"América Mineiro\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Avaí\", \"Bahia\", \"Botafogo\", \"Ceará\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Grêmio\", \"Internacional\", \"Palmeiras\", \"Santos\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2012 = [\"Atlético Goianiense\", \"Atlético Mineiro\", \"Bahia\", \"Botafogo\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Grêmio\", \"Internacional\", \"Náutico\", \"Palmeiras\", \"Ponte Preta\", \"Portuguesa\", \"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\"]\n",
    "camp_2013 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Bahia\", \"Botafogo\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Náutico\", \"Palmeiras\", \"Ponte Preta\", \"Portuguesa\", \"Santos\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2014 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Bahia\", \"Botafogo\", \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Criciúma\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Palmeiras\", \"Santos\", \"São Paulo\", \"Sport\", \"Vitória\"]\n",
    "camp_2015 = [\"Atlético Mineiro\", \"Atlético Paranaense\", \"Avaí\", \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Joinville\", \"Palmeiras\", \"Ponte Preta\", \"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\"]\n",
    "camp_2016 = [\"América Mineiro\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Botafogo\", \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Figueirense\", \"Flamengo\", \"Fluminense\", \"Grêmio\", \"Internacional\", \"Palmeiras\", \"Ponte Preta\", \"Santa Cruz\", \"Santos\", \"São Paulo\", \"Sport\", \"Vitória\"]\n",
    "camp_2017 = [\"Atlético Goianiense\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Avaí\", \"Bahia\", \"Botafogo\", \"Chapecoense\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Flamengo\", \"Fluminense\", \"Grêmio\", \"Palmeiras\", \"Ponte Preta\", \"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\", \"Vitória\"]\n",
    "camp_2018 = [\"América Mineiro\", \"Atlético Mineiro\", \"Atlético Paranaense\", \"Bahia\",\"Botafogo\", \"Ceará\", \"Chapecoense\", \"Corinthians\", \"Cruzeiro\", \"Flamengo\",\"Fluminense\", \"Grêmio\", \"Internacional\", \"Palmeiras\", \"Paraná\",\"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\", \"Vitória\"]\n",
    "camp_2019 = [\"Athletico Paranaense\", \"Atlético Mineiro\", \"Avaí\", \"Bahia\", \"Botafogo\",\"Ceará\", \"Chapecoense\", \"Corinthians\", \"Cruzeiro\", \"CSA\", \"Flamengo\",\"Fluminense\", \"Fortaleza\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Palmeiras\",\"Santos\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2020 = [\"Athletico Paranaense\", \"Atlético Goianiense\", \"Atlético Mineiro\", \"Bahia\",\"Botafogo\", \"Ceará\", \"Corinthians\", \"Coritiba\", \"Flamengo\", \"Fluminense\",\"Fortaleza\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Palmeiras\", \"Bragantino\",\"Santos\", \"São Paulo\", \"Sport\", \"Vasco da Gama\"]\n",
    "camp_2021 = [\"América Mineiro\", \"Athletico Paranaense\", \"Atlético Goianiense\",\"Atlético Mineiro\", \"Bahia\", \"Ceará\", \"Chapecoense\", \"Corinthians\",\"Cuiabá\", \"Flamengo\", \"Fluminense\", \"Fortaleza\", \"Grêmio\", \"Internacional\",\"Juventude\", \"Palmeiras\", \"Bragantino\", \"Santos\", \"São Paulo\", \"Sport\" ]\n",
    "camp_2022 = [\"América Mineiro\", \"Athletico Paranaense\", \"Atlético Goianiense\",\"Atlético Mineiro\", \"Avaí\", \"Botafogo\", \"Ceará\", \"Corinthians\", \"Coritiba\",\"Cuiabá\", \"Flamengo\", \"Fluminense\", \"Fortaleza\", \"Goiás\", \"Internacional\",\"Juventude\", \"Palmeiras\", \"Bragantino\", \"Santos\", \"São Paulo\"]\n",
    "camp_2023 = [\"América Mineiro\", \"Athletico Paranaense\", \"Atlético Mineiro\", \"Bahia\",\"Botafogo\", \"Corinthians\", \"Coritiba\", \"Cruzeiro\", \"Cuiabá\", \"Flamengo\",\"Fluminense\", \"Fortaleza\", \"Goiás\", \"Grêmio\", \"Internacional\", \"Palmeiras\",\"Bragantino\", \"Santos\", \"São Paulo\", \"Vasco da Gama\"]\n",
    "camp_2024 = [\"Athletico Paranaense\", \"Atlético Mineiro\", \"Bahia\", \"Botafogo\",\"Corinthians\", \"Criciúma\", \"Cruzeiro\", \"Cuiabá\", \"Flamengo\", \"Fluminense\",\"Fortaleza\", \"Grêmio\", \"Internacional\", \"Juventude\", \"Palmeiras\",\"Bragantino\", \"Santos\", \"São Paulo\", \"Vasco da Gama\", \"Vitória\"]\n",
    "camp_2025 = [\"Atlético Mineiro\", \"Bahia\", \"Botafogo\",\"Corinthians\", \"Criciúma\", \"Cruzeiro\", \"Cuiabá\", \"Flamengo\", \"Fluminense\",\"Fortaleza\", \"Grêmio\", \"Internacional\", \"Juventude\", \"Palmeiras\",\"Bragantino\", \"Santos\", \"São Paulo\", \"Vasco da Gama\", \"Vitória\"]\n",
    "\n",
    "\n",
    "# Criar uma lista única dos clubes de todos os campeonatos\n",
    "clubes_serie_a = set(camp_2003 + camp_2004 + camp_2005 + camp_2006 + camp_2007 + camp_2008 + camp_2009 + camp_2010 + camp_2011 + camp_2012 + camp_2013 + camp_2014 + camp_2015 + camp_2016 + camp_2017 + camp_2018 + camp_2019 + camp_2020 + camp_2021 + camp_2022 + camp_2023 +camp_2024)\n",
    "\n",
    "print(f\"Total de clubes únicos: {len(clubes_serie_a)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
